Status: 

Tags: [[Algorithms]]

# Big-O Notation

Big O notation is a way to characterize algorithms by focusing on how the algorithm behaves as its input approaches infinity. What we commonly focus on with Big O is how many loops we need to use, which is convenient since one loop would equal O(n) and a nested loop would be O($n^2$) 

This is an intuitive simplification that makes it easier to do [[Measuring Computing Cost|than counting operations]] 
**How to find a Big-O**
- Eliminate all lower order terms
- eliminate/ignore multiplicative constants
- pick only the worst case
- pick some representative operation

# References
[[Measuring Computing Cost]]